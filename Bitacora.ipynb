{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Favor no correr el programa, para no eliminar las imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Santiago Rincón Carreño - 816052 \n",
    "# Bitácora de sistemas inteligentes\n",
    "##### 13/08/2018\n",
    "- Machine learning: Darle la capacidad a un computador para realizar alguna tarea en específico sin necesidad de programarlo específicamente para ello, es decir, que el computador aprende a resolver problemas.\n",
    "-Los tipos de aprendizaje son supervisado y no supervisado:\n",
    "\t- Supervisado: Cuando se entrena la máquina, se conoce cuales datos de entrenamiento **X** generan pertenecen al grupo ${t}_{i}$, los problemas más comunes son de regresión (Se tiene una salida continua) y de clasificación (Se tiene una salida discreta - Pertenencia a una clase).\n",
    "\t- No supervisado: No se tiene información de la pertenencia de $\\textbf{X}$ a una clase ${t}_{i}$, se buscan patrones de $\\textbf{X}$ (Clustering).\n",
    "##### 10/09/2018\n",
    "- Gradiente descendiente: Una técnica para encontrar un mínimo local de una función es realizar movimientos en contra de la dirección de la derivada, con varias iteraciones.   \n",
    "- Neurona: Una neurona es una célula que se encarga de la transmisión de impulsos eléctricos a lo largo del cuerpo. En computación, es un tipo de función que da peso a la información de entrada. \n",
    "- Perceptrón simple: Es un conjunto de neuronas. Tiene 3 etapas: Dar peso a los datos de entrada ${x}_{i}{w}_{i}$, una suma de los datos de entrada por los pesos $\\textbf{w}^{T}\\textbf{x}$  (Con $\\textbf{x}$ como datos de entrada y $\\textbf{w}$ pesos de las neuronas) y finalmente una función de activación $\\phi$. Si y es la salida de la red neuronal: $y=\\phi\\{\\textbf{w}^{T}\\textbf{x}\\}$. Se agrega una característica de unos a  $\\textbf{x}$ (Bias), porque puede que el modelo sea afín.\n",
    "<center>\n",
    "<img src=perceptron.PNG>\n",
    "Figura 1. Perceptrón simple\n",
    "</center>\n",
    "\n",
    "##### 24/09/2018 \n",
    "- Hipótesis: Se define la hipótesis como la función que relaciona los datos de entrada con la salida ($y={h}_{\\textbf{w}}(\\textbf{x})=\\phi{\\{\\textbf{w}^{T}\\textbf{x}}\\}$).\n",
    "-  La función de costo: Se define como una función de error $J(w)=\\frac{1}{2m}\\sum{({h}_{\\textbf{w}}(\\textbf{x}_{i})-{y}_{di})^{2}}$, donde $\\textbf{x}_{i}$ es la i-ésima muestra y ${y}_{di}$ es la salida deseada, es decir el promedio de los errores cuadráticos. Se busca hallar el mínimo de esta función, para ello se utiliza el algoritmo de gradiente descendiente con un tamaño de paso $\\alpha$.\n",
    "<center>\n",
    "<img src=costo.PNG>\n",
    "Figura 2. Función de costo para dos pesos ${w}_{0}$ y ${w}_{1}$.\n",
    "</center>\n",
    "- Función de activación: Existen muchas funciones, entre ellas están las hard limiter (Como signo o escalón unitario), la tangente hiperbólica, rectificada lineal, etc. Las hard limiter no son de derivada continua, por ello se prefiere utilizar otras.\n",
    "-  Red neuronal:  Se agregan neuronas como nuevas capas o como neuronas adicionales a una capa. Cuando la red tiene muchas capas ocultas se habla de Deep Learning. La actualización de los pesos, por medio del gradiente descendiente, se hace en función del error de la salida ya que no se pueden tener mediciones de error en las capas ocultas.\n",
    "- Regresión lineal: (Problema: Reconstruir una función seno) Se asume una hipóstesis ${h}_{\\textbf{w}}(\\textbf{x})=\\sum{{w}_{i}{x}_{i}}$  (Donde ${w}_{0}$ es el valor del bias y ${x}_{0}$=1) y se aplica el algortimo de gradiente descendiente (Solo requiere de una capa). Una alternativa al gradiente descendiente es aplicar la ecuación normal para hallar $\\textbf{w}$ ($\\textbf{w}=(\\textbf{X}^{T}\\textbf{X})^{-1}\\textbf{X}^{T}\\textbf{y}$). Se utiliza la ecuación normal cuando se tienen más muestras que características (Por lo general, para matrices $\\textbf{X}$ no muy grandes, debido al costo computacional). Como la función seno no es lineal, se puede modificar el conjunto de entrada y utilizar la regresión lineal.\n",
    "<center>\n",
    "<img src=\"lr.PNG\" width=\"500\">\n",
    "Figura 3. Ejemplo de regresión lineal.\n",
    "</center>\n",
    "\n",
    "##### 21/01/19\n",
    "- Inteligencia artificial generalizada: Cuando se de alcance la capacidad de razonamiento de las personas, procesamiento de imágenes al nivel que lo hago un cerebro humano, decir oraciones CON SENTIDO, etc.\n",
    "- Superinteligencia artificial: Excede la capacidad de razonamiento de las personas, como es capaz de programar, se rediseña (O corrige) por sí mismo.\n",
    "\n",
    "- ### Repaso: \n",
    "\t- Neurona: Tiene entradas, a las cuales se les asignan ciertos pesos, porsteriormente se hace una suma ponderada y se utiliza una función de activación.\n",
    "\t- Gradiente descendiente: se utiliza para moverse sobre la superficie de la función de costo, con el fin de encontrar un mínimo (Movimientos en dirección opuesta a la derivada). Al hallar el mínimo, se da valores que optimicen el problema a los pesos. El tamaño del paso es determinante para encontrar el mínimo. \n",
    "\n",
    "- Gradiente estocástico: Toma muestras de la población.\n",
    "- Momentum : Un movimiento que requiere de memoria, permite que no se cambie instantáneamente de dirección, es decir, que no se presenten cambios abruptos en el movimiento.\n",
    "\n",
    "##### 28/01/2019\n",
    "- Se pueden presentar casos en los que el método del gradiente descendiente no es muy efectivo, esto es: a) No puede hallar un mínimo absoluto pasando por uno local ó b) La magnitud del gradiente es muy pequeña (Zonas de la función de costo en donde la función de costo es muy 'plana').\n",
    "- Superficies de contorno: Forma de ver una función multidimensional sobre un plano, indicando con distintos colores la energía o amplitud (proyectada sobre dicho plano).  \n",
    "<center>\n",
    "<img src=\"level.PNG\" width=\"500\">\n",
    "Figura 4. Curvas de nivel o superficie de contorno.\n",
    "</center>\n",
    "- Si el algoritmo tiene momentum se demora menos (Requiere de menos épocas), si el tamaño de paso es muy grande, la salida oscila, pero el método es muy efectivo.\n",
    "\n",
    "- Hay diferentes métodos para entrenar el modelo: No. de capas, No. de neuronas por capa, No. de épocas, Función de activación y Optimizadores.\n",
    "- Función de perdida: Forma de calcular el error (Se utilizan por lo general funciones que miden la entropía).\n",
    "- Redes neuronales convolucionales: Muy buenas para trabajar con imágenes. Una capa de dicha red se encarga de aplicar filtros en ventanas deslizantes sobre la imagen de entrada, de tal manera que las dimensiones de la imagen disminuyen, pero aumenta su profundidad. Posteriormente se hace un submuestreo para disminuir aun más el tamaño de la imagen. Se aplican varias capas de este tipo y posteriormente se tiene una red normal (Puede ser un perceptrón).\n",
    "  - Lirería a utilizar Keras en python para Redes Neuronales (Tensorflow tiene núcleo de keras).\n",
    "\n",
    "##### 11/02/2019\n",
    "#### K-means: \n",
    "- Se desea encontrar grupos con patrones similares dentro del set de datos **X** (clusters). El objetivo de K-means es encontrar K centroides; la idea es organizar los centroides, de tal manera que se ubiquen en puntos de gran concentración de datos. Se asigna un dato de entrada al cluster en que la distancia a su centroide sea la menor entre todos los centroides. \n",
    "- En la clase se propone desorganizar los datos de entrada, para un mejor rendimiento (_Considero_ innecesario este paso, según lo observado en algunos ejemplos de internet, un ejemplo es https://mubaris.com/posts/kmeans-clustering/)\n",
    "<center>\n",
    "<img src=\"k2.JPEG\" width=\"500\">\n",
    "Figura 5. Centroides \n",
    "</center>\n",
    "\n",
    "<center>\n",
    "<img src=k-medias.PNG>\n",
    "Figura 6. Clusters\n",
    "</center>\n",
    "\n",
    "\n",
    "##### 25/02/2019\n",
    "#### Mapas autoasociativos: \n",
    "- Es K-means con \"bandas elásticas\". Se tiene un espacio de entrada y uno de salida, en el espacio de entrada se mueven los centroides, mientras que en el espacio de salida los centroides los centroides están siempre ordenados (Los centroides se mueven en el espacio de entrada y el peso se calcula en el de salida).\n",
    "- Se puede interpretar cada cluster de mejor manera que en K-means.\n",
    "- Si se inicializan los centroides en : a) Cero, puede que los centroides nunca se muevan, b) Puntos aleatorios, no se garantiza que los puntos coincidan con el espacio de entrada (Fuera de dimensión), c) En el valor medio de los datos con cambios aleatorios, etc. Cuando se incializan los pesos como en c), se tiene un desempeño muy bueno del algoritmo.\n",
    "- Cuando un centroide se mueve, \"arrastra\" a los demás centroides en el espacio de salida. Suponer que la variación de los pesos centroides en el espacio de salida está dada por una Gaussiana: \n",
    "<center>\n",
    "<img src=\"som2.JPEG\" width=\"500\">\n",
    "Figura 7. Espacio de salida\n",
    "</center>\n",
    "Cuando $\\sigma$ tiende a cero, el algoritmo se convierte en K-medias, mientras que cuando tiene a 1, se tiene muchas rigidez (Es decir que si que los centroides tienen poca elasticidad). Una solución puede ser utilizar un factor de decaimiento (Con cada iteración), que es escalar el factor de peso de la función del espacio de salida.\n",
    "\n",
    "<center>\n",
    "<img src=som1.PNG>\n",
    "Figura 8. Resultados en el espacio de entrada.\n",
    "</center>\n",
    "\n",
    "##### 04/03/2019\n",
    "#### Lógica difusa:\n",
    "Es un control utilizado cuando es difícil formalizar el proceso, se hace en busca obtener consistencia a partir del conocimiento empírico.\n",
    "Es necesario definir umbrales de cuando una condición se cumple o no.\n",
    "Se tienen conjuntos difusos y no cerrados (Que toman diferentes valores de acuerdo a una medida relativa).\n",
    "La función de membresia ($\\mu$), define el conjunto difuso, salida entre 0 y 1. Las funciones de membresía  pueden ser convexas (Dados dos puntos de la curva, la recta que las une queda por debajo de la curva y ningún punto queda por debajo de la recta) ó no convexa (Pero que no tenga un mínimo entre 2 máximos.)\n",
    "La variable a estudiar se denomina variable lingüística (Definida por un rango y por conjuntos difusos\n",
    "-> cada conjunto se asocia a una variable lingüística. El rango es conocido como univeso de discurso.\n",
    "\n",
    "\n",
    "        Baj@              Alt@\n",
    "      ------------    -------------\n",
    "                  \\  /\n",
    "  \t\t         \\/ \n",
    "\t\t           /\\\n",
    "\t \t         /  \\\n",
    "\t  ------------    -------------  Altura(cm)\n",
    "               140    190  \n",
    "     Figura 9. Conjuntos de variables lingüísticas.\n",
    "               \n",
    "Sistema de inferencia difuso: Un conjunto de variables lingüísticas generan REGLAS, de las cuales se obtiene un resultado.\n",
    "\n",
    "Reglas: Operan por reglas matemáticas [Composiciones, Agregaciones, disyunción/conjunción]\n",
    "Resultado: Puede ser una variable lingüística (Sistema de tipo Mamdani) o un número (Takagi-Sugeno-Kang).\n",
    "\n",
    "- En general: Si p->q, hacer algo. Por ejemplo: \n",
    "\n",
    "Si h>180 -> Es alt@. No es correcto decir que si h<=180->no es alt@. \n",
    "\n",
    "\n",
    "\n",
    "#### Datos sintéticos: \n",
    "Son datos creados por computadora, simulando situaciones de la vida real (Según el usuario que simule).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
